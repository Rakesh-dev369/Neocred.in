{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Modeling with Imbalanced Learning\n",
    "\n",
    "Advanced credit risk modeling focusing on class imbalance handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from data_science.imbalanced_learning import ImbalancedLearningHandler\n",
    "from data_science.visualization import FinancialVisualizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Credit Risk Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic credit risk dataset with severe imbalance\n",
    "np.random.seed(42)\n",
    "n_samples = 5000\n",
    "\n",
    "# Generate features\n",
    "data = {\n",
    "    'age': np.random.randint(18, 70, n_samples),\n",
    "    'income': np.random.lognormal(10.5, 0.6, n_samples),\n",
    "    'debt_ratio': np.random.beta(2, 5, n_samples),\n",
    "    'credit_history_length': np.random.randint(0, 30, n_samples),\n",
    "    'num_credit_lines': np.random.poisson(3, n_samples),\n",
    "    'credit_utilization': np.random.beta(2, 3, n_samples)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create realistic default probability (highly imbalanced)\n",
    "default_prob = (\n",
    "    0.01 +  # Base rate\n",
    "    0.15 * (df['debt_ratio'] > 0.4) +  # High debt ratio\n",
    "    0.10 * (df['credit_utilization'] > 0.8) +  # High utilization\n",
    "    0.05 * (df['credit_history_length'] < 2) +  # Short history\n",
    "    0.08 * (df['income'] < 30000)  # Low income\n",
    ")\n",
    "\n",
    "df['default'] = np.random.binomial(1, default_prob, n_samples)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Default rate: {df['default'].mean():.2%}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Learning Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize handlers\n",
    "imb = ImbalancedLearningHandler()\n",
    "viz = FinancialVisualizer()\n",
    "\n",
    "# Analyze imbalance\n",
    "imbalance_analysis = imb.analyze_imbalance(df['default'])\n",
    "print(\"Class Imbalance Analysis:\")\n",
    "for key, value in imbalance_analysis.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Visualize class distribution\n",
    "class_fig = viz.plot_class_distribution(df['default'], \"Credit Default Distribution\")\n",
    "class_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Sampling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "features = ['age', 'income', 'debt_ratio', 'credit_history_length', 'num_credit_lines', 'credit_utilization']\n",
    "X = df[features]\n",
    "y = df['default']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Compare sampling methods\n",
    "comparison = imb.compare_sampling_methods(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame({\n",
    "    'Method': list(comparison.keys()),\n",
    "    'ROC-AUC': [results['roc_auc'] for results in comparison.values()],\n",
    "    'F1-Score': [results['classification_report']['1']['f1-score'] for results in comparison.values()],\n",
    "    'Precision': [results['classification_report']['1']['precision'] for results in comparison.values()],\n",
    "    'Recall': [results['classification_report']['1']['recall'] for results in comparison.values()],\n",
    "    'Training_Samples': [results['training_samples'] for results in comparison.values()]\n",
    "})\n",
    "\n",
    "print(\"Sampling Methods Comparison:\")\n",
    "print(results_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best performing model\n",
    "X_smote, y_smote = imb.apply_smote(X_train, y_train)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf.fit(X_smote, y_smote)\n",
    "\n",
    "# Get probabilities\n",
    "y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Find optimal threshold\n",
    "threshold_analysis = imb.get_optimal_threshold(y_test.values, y_prob)\n",
    "\n",
    "print(\"Optimal Threshold Analysis:\")\n",
    "for key, value in threshold_analysis.items():\n",
    "    print(f\"{key}: {value:.3f}\")\n",
    "\n",
    "# Apply optimal threshold\n",
    "y_pred_optimal = (y_prob >= threshold_analysis['optimal_threshold']).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report with Optimal Threshold:\")\n",
    "print(classification_report(y_test, y_pred_optimal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance plots\n",
    "performance_plots = viz.plot_model_performance(y_test.values, y_pred_optimal, y_prob)\n",
    "\n",
    "# Display plots\n",
    "for plot_name, fig in performance_plots.items():\n",
    "    fig.show()\n",
    "    print(f\"\\n{plot_name} displayed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance for Credit Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance for Credit Risk:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "importance_fig = viz.plot_feature_importance(\n",
    "    feature_importance['feature'].tolist(),\n",
    "    feature_importance['importance'].tolist()\n",
    ")\n",
    "importance_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated advanced credit risk modeling with focus on:\n",
    "\n",
    "1. **Severe Class Imbalance**: Realistic 5% default rate\n",
    "2. **Multiple Sampling Techniques**: SMOTE, ADASYN, combined methods\n",
    "3. **Optimal Threshold Selection**: Maximizing F1-score for imbalanced data\n",
    "4. **Performance Visualization**: ROC curves, confusion matrices\n",
    "5. **Feature Importance**: Key risk factors identification\n",
    "\n",
    "Key findings:\n",
    "- SMOTE typically performs best for credit risk datasets\n",
    "- Optimal threshold differs from default 0.5\n",
    "- Debt ratio and credit utilization are top risk factors\n",
    "- Balanced models improve minority class detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}